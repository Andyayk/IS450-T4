{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Before closing, go to Cell > All Output > Clear to keep file size small.\n",
    "\n",
    "Also make sure this jupyter notebook file is opened using the following command:\n",
    "\n",
    "```jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000000```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Import all libraries and reading explored data into Dataframe</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T13:49:14.197888Z",
     "start_time": "2018-11-02T13:49:12.900261Z"
    }
   },
   "outputs": [],
   "source": [
    "import re, io, gensim, datetime, time, nltk\n",
    "from gensim import corpora\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#General libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Libraries for data pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Libraries for data pre-processing (Log Loss)\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "#For Decision Tree implementation\n",
    "from scipy.stats import entropy\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "#For KNN implementation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#For Bagging implementation\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#For AdaBoost implementation\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#For Random Forest implementation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#For Baseline implementation\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#For Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#For Ensemble\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#Settings\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "sns.set()\n",
    "\n",
    "def printModelAccuracy(y_test, y_pred):\n",
    "    # Find the confusion matrix of the result\n",
    "    cm = pd.DataFrame(confusion_matrix(y_test, y_pred, labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), \\\n",
    "        index=['true:0', 'true:1', 'true:2', 'true:3', 'true:4', 'true:5', 'true:6', 'true:7', 'true:8', 'true:9', 'true:10', 'true:11'], \n",
    "        columns=['pred:0', 'pred:1', 'pred:2', 'pred:3', 'pred:4', 'pred:5', 'pred:6', 'pred:7', 'pred:8', 'pred:9', 'pred:10', 'pred:11'])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Find the accuracy and F1 score of the result\n",
    "    asr = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(\"Accuracy:\", asr)\n",
    "    print(\"F1:\", f1)\n",
    "    \"\"\"\n",
    "    # Log loss\n",
    "    score = log_loss(y_test, y_pred)\n",
    "    print(\"Log Loss:\", score)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216.2837860584259\n",
      "['nyx sex bomb pallet natur palett', 'etud hous preciou miner cushion pearl aura puff', 'milani rose powder blush', 'etud hous babi sweet sugar powder', 'bedak revlon color stay aqua miner make', 'dr pure whiten cream', 'chanel powder blush malic', 'snail white cream origin', 'sunpris proof spf', 'eyebrow powder nyx satuan rp pc']\n"
     ]
    }
   ],
   "source": [
    "# Takes around 7 minutes\n",
    "all_df = pd.read_csv(\"train.csv\",header = 0)\n",
    "corpus = all_df[\"title\"]\n",
    "labels = all_df[\"Category\"]\n",
    "\n",
    "start = time.time()\n",
    "stop_list = nltk.corpus.stopwords.words('english')\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "def corpus2docs(corpus):\n",
    "    # corpus is a object returned by load_corpus that represents a corpus.\n",
    "    docs1 = []\n",
    "\n",
    "    for title in corpus:\n",
    "        doc = nltk.word_tokenize(title)\n",
    "        docs1.append(doc)\n",
    "    docs2 = [[w.lower() for w in doc] for doc in docs1] #lower case the words\n",
    "    docs3 = [[w for w in doc if re.search('^[a-z]+$', w)] for doc in docs2] #removing special characters and numbers\n",
    "    docs4 = [[w for w in doc if w not in stop_list] for doc in docs3] #removing words in stop list\n",
    "    #changing list into a string\n",
    "    docs5 = [' '.join([stemmer.stem(w) for w in doc]) for doc in docs4] #changing the words into its root form\n",
    "    \n",
    "    return docs5\n",
    "\n",
    "docs = corpus2docs(corpus)\n",
    "end = time. time()\n",
    "print(end - start)\n",
    "print(docs[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Vectorise and TFIDF words</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    aa  aaa  aag  aaw   ab abadi abal  abc  abh abil   ...      zs  zsc   zt  \\\n",
      "0 0.00 0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00 0.00   ...    0.00 0.00 0.00   \n",
      "1 0.00 0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00 0.00   ...    0.00 0.00 0.00   \n",
      "2 0.00 0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00 0.00   ...    0.00 0.00 0.00   \n",
      "3 0.00 0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00 0.00   ...    0.00 0.00 0.00   \n",
      "4 0.00 0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00 0.00   ...    0.00 0.00 0.00   \n",
      "5 0.00 0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00 0.00   ...    0.00 0.00 0.00   \n",
      "6 0.00 0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00 0.00   ...    0.00 0.00 0.00   \n",
      "7 0.00 0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00 0.00   ...    0.00 0.00 0.00   \n",
      "8 0.00 0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00 0.00   ...    0.00 0.00 0.00   \n",
      "9 0.00 0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00 0.00   ...    0.00 0.00 0.00   \n",
      "\n",
      "   ztv  zvf zwain zwgb zwitsal zxcv Category  \n",
      "0 0.00 0.00  0.00 0.00    0.00 0.00        0  \n",
      "1 0.00 0.00  0.00 0.00    0.00 0.00        1  \n",
      "2 0.00 0.00  0.00 0.00    0.00 0.00        2  \n",
      "3 0.00 0.00  0.00 0.00    0.00 0.00        3  \n",
      "4 0.00 0.00  0.00 0.00    0.00 0.00        3  \n",
      "5 0.00 0.00  0.00 0.00    0.00 0.00        4  \n",
      "6 0.00 0.00  0.00 0.00    0.00 0.00        2  \n",
      "7 0.00 0.00  0.00 0.00    0.00 0.00        4  \n",
      "8 0.00 0.00  0.00 0.00    0.00 0.00        4  \n",
      "9 0.00 0.00  0.00 0.00    0.00 0.00        3  \n",
      "\n",
      "[10 rows x 7853 columns]\n",
      "0.9412262439727783\n"
     ]
    }
   ],
   "source": [
    "# Takes around 2 minutes\n",
    "start = time.time()\n",
    "\n",
    "def convertToDataframe(listofwords, labels):\n",
    "    vectorizer = TfidfVectorizer(analyzer='word') #tfidf\n",
    "    words_tfidf = vectorizer.fit_transform(listofwords) #tfidf\n",
    "\n",
    "    tablecolumns = []                      \n",
    "    tablecolumns.append(vectorizer.get_feature_names()) #adding column headers\n",
    "\n",
    "    df = pd.DataFrame(words_tfidf.toarray(), columns=tablecolumns) #creating dataframe\n",
    "\n",
    "    df['Category'] = labels\n",
    "                      \n",
    "    return df\n",
    "\n",
    "\n",
    "df = convertToDataframe(docs[0:50000], labels.values.tolist()[0:50000]) #limit for 50k rows\n",
    "print(df.head(10))\n",
    "\n",
    "end = time. time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train-Test Split</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T13:49:14.651188Z",
     "start_time": "2018-11-02T13:49:14.642104Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'Category'] #take everything except Category\n",
    "\n",
    "y = df[['Category']] #our label is Category\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Baseline Classifier (Decision Tree)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "         pred:0  pred:1  pred:2  pred:3  pred:4  pred:5  pred:6  pred:7  \\\n",
      "true:0      180       0       0       0       0       0       0       0   \n",
      "true:1        0    1051       0       0       0       0       0       0   \n",
      "true:2        0       0     448       0       0       0       0       0   \n",
      "true:3        0       0       0    3158       0       0       0       0   \n",
      "true:4        0       0       0       0    1654       0       0       0   \n",
      "true:5        0       0       0       0       0    2150       0       0   \n",
      "true:6        0       0       0       0       0       0       0      82   \n",
      "true:7        0       0       0       0       0       0       0     464   \n",
      "true:8        0       0       0       0       0       0       0       0   \n",
      "true:9        0       0       0       0       0       0       0       0   \n",
      "true:10       0       0       0       0       0       0       0       0   \n",
      "true:11       0       0       0       0       0       0       0       0   \n",
      "\n",
      "         pred:8  pred:9  pred:10  pred:11  \n",
      "true:0        0       0        0        0  \n",
      "true:1        0       0        0        0  \n",
      "true:2        0       0        0        0  \n",
      "true:3        0       0        0        0  \n",
      "true:4        0       0        0        0  \n",
      "true:5        0       0        0        0  \n",
      "true:6        0       0        0        0  \n",
      "true:7        0       0        0        0  \n",
      "true:8        0     239        0        0  \n",
      "true:9        0     361        0        0  \n",
      "true:10       0      47        0        0  \n",
      "true:11       0     166        0        0  \n",
      "Accuracy: 0.9466\n",
      "F1: 0.6278169469417129\n",
      "Best Parameters: {'max_depth': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'max_depth' : list(range(1, 5))\n",
    "}\n",
    "\n",
    "decisionTree = GridSearchCV(DecisionTreeClassifier(), cv=3, param_grid=parameters, scoring='f1_macro')\n",
    "#Fit the training feature Xs and training label Ys\n",
    "decisionTree.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = decisionTree.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)\n",
    "\n",
    "# Best hyperparameters to use for model\n",
    "print(\"Best Parameters:\",decisionTree.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>AdaBoost (with Decision Tree)</h1>\n",
    "\n",
    "Refer to the following links on for detail explanation on the implementation:\n",
    "- [AdaBoost Classifier SKLearn Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
    "- [DataCamp Implementation](https://www.datacamp.com/community/tutorials/adaboost-classifier-python)\n",
    "- [Setting Learning Rate and N Estimators](https://stats.stackexchange.com/questions/82323/shrinkage-parameter-in-adaboost)\n",
    "\n",
    "*Note that the default AdaBoost implementation in SKLearn is Decision Tree \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T13:56:38.864454Z",
     "start_time": "2018-11-02T13:56:38.853524Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "         pred:0  pred:1  pred:2  pred:3  pred:4  pred:5  pred:6  pred:7  \\\n",
      "true:0      180       0       0       0       0       0       0       0   \n",
      "true:1        0    1051       0       0       0       0       0       0   \n",
      "true:2        0       0       0     448       0       0       0       0   \n",
      "true:3        0       0       0    3158       0       0       0       0   \n",
      "true:4        0       0       0       0    1654       0       0       0   \n",
      "true:5        0       0       0       0       0    2150       0       0   \n",
      "true:6        0       0       0       0       0       0      82       0   \n",
      "true:7        0       0       0       0       0       0       0     464   \n",
      "true:8        0       0       0       0       0       0       0     239   \n",
      "true:9        0       0       0       0       0       0       0     361   \n",
      "true:10       0       0       0       0       0       0       0      47   \n",
      "true:11       0       0       0       0       0       0       0       0   \n",
      "\n",
      "         pred:8  pred:9  pred:10  pred:11  \n",
      "true:0        0       0        0        0  \n",
      "true:1        0       0        0        0  \n",
      "true:2        0       0        0        0  \n",
      "true:3        0       0        0        0  \n",
      "true:4        0       0        0        0  \n",
      "true:5        0       0        0        0  \n",
      "true:6        0       0        0        0  \n",
      "true:7        0       0        0        0  \n",
      "true:8        0       0        0        0  \n",
      "true:9        0       0        0        0  \n",
      "true:10       0       0        0        0  \n",
      "true:11       0       0        0      166  \n",
      "Accuracy: 0.8905\n",
      "F1: 0.6269144459150372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Create the AdaBoost classifier. Default base classifiers is Decision Tree. \n",
    "# - n_estimator is the number of base classifiers (i.e. weak learners)\n",
    "# - learning_rate controls the weight adjustments of each base classifiers. Default is 1\n",
    "adaboostTree = AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "adaboostTree.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = adaboostTree.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>AdaBoost (with Naive Bayes)</h1>\n",
    "\n",
    "Refer to the following links on for detail explanation on the implementation:\n",
    "- [Gaussian Naive Bayes Classifier SKLearn Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n",
    "- [Naive Bayes Classifier video](https://www.youtube.com/watch?v=CPqOCI0ahss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "         pred:0  pred:1  pred:2  pred:3  pred:4  pred:5  pred:6  pred:7  \\\n",
      "true:0       29      78      10      20      28       6       0       1   \n",
      "true:1        0     585       4     217      55     168       0      17   \n",
      "true:2        0       3     260     106      29      28       0      10   \n",
      "true:3        0       3       2    2761     103     277       0       6   \n",
      "true:4        0       0       0     172    1159     281       0      29   \n",
      "true:5        0       0       0     122     247    1775       0       6   \n",
      "true:6        0       0       0      20      10       3       0      44   \n",
      "true:7        0       0       0      47      64      98       0     252   \n",
      "true:8        0       0       0      86      31      26       0      56   \n",
      "true:9        0       0       0      48      85     156       0       7   \n",
      "true:10       0       0       0       4      24      19       0       0   \n",
      "true:11       0       0       0      55      33      49       0      27   \n",
      "\n",
      "         pred:8  pred:9  pred:10  pred:11  \n",
      "true:0        8       0        0        0  \n",
      "true:1        2       3        0        0  \n",
      "true:2       11       1        0        0  \n",
      "true:3        3       3        0        0  \n",
      "true:4        7       5        0        1  \n",
      "true:5        0       0        0        0  \n",
      "true:6        3       0        0        2  \n",
      "true:7        2       1        0        0  \n",
      "true:8       38       1        0        1  \n",
      "true:9        1      64        0        0  \n",
      "true:10       0       0        0        0  \n",
      "true:11       1       0        0        1  \n",
      "Accuracy: 0.6924\n",
      "F1: 0.4118468473618267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "naivebayes = MultinomialNB()\n",
    "#Fit the training feature Xs and training label Ys\n",
    "naivebayes.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = naivebayes.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "         pred:0  pred:1  pred:2  pred:3  pred:4  pred:5  pred:6  pred:7  \\\n",
      "true:0        0       0       0       0     180       0       0       0   \n",
      "true:1        0       0       0       0    1051       0       0       0   \n",
      "true:2        0       0       0       0     448       0       0       0   \n",
      "true:3        0       0       0       0       0    3158       0       0   \n",
      "true:4        0       0       0       0       0    1654       0       0   \n",
      "true:5        0       0       0       0       0    2150       0       0   \n",
      "true:6        0       0       0       0       0       0      82       0   \n",
      "true:7        0       0       0       0       0       0       0       0   \n",
      "true:8        0       0       0       0       0       0       0       5   \n",
      "true:9        0       0       0       0       0       0       0     361   \n",
      "true:10       0       0       0       0       0       0       0       0   \n",
      "true:11       0       0       0       0       0       0       0       0   \n",
      "\n",
      "         pred:8  pred:9  pred:10  pred:11  \n",
      "true:0        0       0        0        0  \n",
      "true:1        0       0        0        0  \n",
      "true:2        0       0        0        0  \n",
      "true:3        0       0        0        0  \n",
      "true:4        0       0        0        0  \n",
      "true:5        0       0        0        0  \n",
      "true:6        0       0        0        0  \n",
      "true:7      464       0        0        0  \n",
      "true:8      234       0        0        0  \n",
      "true:9        0       0        0        0  \n",
      "true:10       0      47        0        0  \n",
      "true:11       0     166        0        0  \n",
      "Accuracy: 0.2466\n",
      "F1: 0.16428096350440655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "adaboostnaivebayes = AdaBoostClassifier(n_estimators=50,learning_rate=1, base_estimator=nb)\n",
    "#model = BaggingClassifier(n_estimators=50, base_estimator=knn)\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "adaboostnaivebayes.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = adaboostnaivebayes.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
