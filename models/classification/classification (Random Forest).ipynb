{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (Classification Tree technique)\n",
    "\n",
    "In this notebook we will focus on performing a Supervised Learning algorithm known as \"Random Forest\" to build a predictive model.\n",
    "\n",
    "There are a few steps to be followed to train a model for testing:\n",
    "\n",
    "1) Decide on dataset to be used for training and read as a dataframe <br>\n",
    "2) Pre-process dataset <br>\n",
    "3) Dataset partitioning into training, test and validation datasets <br>\n",
    "4) Train predictive model using Random Forest classifier <br>\n",
    "5) Do prediction on test dataset <br>\n",
    "6) Perform evaluation techniques (i.e. Confusion Matrix, F1 score etc) <br>\n",
    "7) Make improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Before closing, go to Cell > All Output > Clear to keep file size small.\n",
    "\n",
    "Also make sure this jupyter notebook file is opened using the following command:\n",
    "\n",
    "```jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000000```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing of general libraries needed\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import gensim, datetime, time\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "#Libraries for data pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#For Random Forest implementation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def printModelAccuracy(y_test, y_pred):\n",
    "    # Find the confusion matrix of the result\n",
    "    cm = pd.DataFrame(confusion_matrix(y_test, y_pred, labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), \\\n",
    "        index=['true:0', 'true:1', 'true:2', 'true:3', 'true:4', 'true:5', 'true:6', 'true:7', 'true:8', 'true:9', 'true:10', 'true:11'], \n",
    "        columns=['pred:0', 'pred:1', 'pred:2', 'pred:3', 'pred:4', 'pred:5', 'pred:6', 'pred:7', 'pred:8', 'pred:9', 'pred:10', 'pred:11'])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Find the accuracy and F1 score of the result\n",
    "    asr = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(\"Accuracy:\", asr)\n",
    "    print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>title</th>\n",
       "      <th>Category</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307504</td>\n",
       "      <td>nyx sex bomb pallete natural palette</td>\n",
       "      <td>0</td>\n",
       "      <td>beauty_image/6b2e9cbb279ac95703348368aa65da09.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>461203</td>\n",
       "      <td>etude house precious mineral any cushion pearl...</td>\n",
       "      <td>1</td>\n",
       "      <td>beauty_image/20450222d857c9571ba8fa23bdedc8c9.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3592295</td>\n",
       "      <td>milani rose powder blush</td>\n",
       "      <td>2</td>\n",
       "      <td>beauty_image/6a5962bed605a3dd6604ca3a4278a4f9.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4460167</td>\n",
       "      <td>etude house baby sweet sugar powder</td>\n",
       "      <td>3</td>\n",
       "      <td>beauty_image/56987ae186e8a8e71fcc5a261ca485da.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5853995</td>\n",
       "      <td>bedak revlon color stay aqua mineral make up</td>\n",
       "      <td>3</td>\n",
       "      <td>beauty_image/9c6968066ebab57588c2f757a240d8b9.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    itemid                                              title  Category  \\\n",
       "0   307504               nyx sex bomb pallete natural palette         0   \n",
       "1   461203  etude house precious mineral any cushion pearl...         1   \n",
       "2  3592295                           milani rose powder blush         2   \n",
       "3  4460167                etude house baby sweet sugar powder         3   \n",
       "4  5853995       bedak revlon color stay aqua mineral make up         3   \n",
       "\n",
       "                                          image_path  \n",
       "0  beauty_image/6b2e9cbb279ac95703348368aa65da09.jpg  \n",
       "1  beauty_image/20450222d857c9571ba8fa23bdedc8c9.jpg  \n",
       "2  beauty_image/6a5962bed605a3dd6604ca3a4278a4f9.jpg  \n",
       "3  beauty_image/56987ae186e8a8e71fcc5a261ca485da.jpg  \n",
       "4  beauty_image/9c6968066ebab57588c2f757a240d8b9.jpg  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read & import dataset as dataframe\n",
    "dataset_df = pd.read_csv('train.csv', header=0)\n",
    "\n",
    "#Display first 5 rows\n",
    "dataset_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210.69733667373657\n",
      "['nyx sex bomb pallet natur palett', 'etud hous preciou miner cushion pearl aura puff', 'milani rose powder blush', 'etud hous babi sweet sugar powder', 'bedak revlon color stay aqua miner make', 'dr pure whiten cream', 'chanel powder blush malic', 'snail white cream origin', 'sunpris proof spf', 'eyebrow powder nyx satuan rp pc']\n"
     ]
    }
   ],
   "source": [
    "#Data pre-processing\n",
    "#Takes around 4 minutes to run this block of code\n",
    "corpus = dataset_df[\"title\"]\n",
    "labels = dataset_df[\"Category\"]\n",
    "\n",
    "start = time.time()\n",
    "stop_list = nltk.corpus.stopwords.words('english')\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "def corpus2docs(corpus):\n",
    "    # corpus is a object returned by load_corpus that represents a corpus.\n",
    "    docs1 = []\n",
    "\n",
    "    for title in corpus:\n",
    "        doc = nltk.word_tokenize(title)\n",
    "        docs1.append(doc)\n",
    "    docs2 = [[w.lower() for w in doc] for doc in docs1] #lower case the words\n",
    "    docs3 = [[w for w in doc if re.search('^[a-z]+$', w)] for doc in docs2] #removing special characters and numbers\n",
    "    docs4 = [[w for w in doc if w not in stop_list] for doc in docs3] #removing words in stop list\n",
    "    #changing list into a string\n",
    "    docs5 = [' '.join([stemmer.stem(w) for w in doc]) for doc in docs4] #changing the words into its root form\n",
    "    \n",
    "    return docs5\n",
    "\n",
    "docs = corpus2docs(corpus)\n",
    "end = time. time()\n",
    "print(end - start)\n",
    "print(docs[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    aa  aaa  aag  aaw   ab abadi abal  abc  abh abil   ...      zs  zsc   zt  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
      "1  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
      "2  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
      "3  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
      "4  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
      "5  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
      "6  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
      "7  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
      "8  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
      "9  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
      "\n",
      "   ztv  zvf zwain zwgb zwitsal zxcv Category  \n",
      "0  0.0  0.0   0.0  0.0     0.0  0.0        0  \n",
      "1  0.0  0.0   0.0  0.0     0.0  0.0        1  \n",
      "2  0.0  0.0   0.0  0.0     0.0  0.0        2  \n",
      "3  0.0  0.0   0.0  0.0     0.0  0.0        3  \n",
      "4  0.0  0.0   0.0  0.0     0.0  0.0        3  \n",
      "5  0.0  0.0   0.0  0.0     0.0  0.0        4  \n",
      "6  0.0  0.0   0.0  0.0     0.0  0.0        2  \n",
      "7  0.0  0.0   0.0  0.0     0.0  0.0        4  \n",
      "8  0.0  0.0   0.0  0.0     0.0  0.0        4  \n",
      "9  0.0  0.0   0.0  0.0     0.0  0.0        3  \n",
      "\n",
      "[10 rows x 7853 columns]\n",
      "1.2884414196014404\n"
     ]
    }
   ],
   "source": [
    "#Data pre-processing - vectorise and TF-IDF\n",
    "start = time.time()\n",
    "\n",
    "def convertToDataframe(listofwords, labels):\n",
    "    vectorizer = TfidfVectorizer(analyzer='word') #tfidf\n",
    "    words_tfidf = vectorizer.fit_transform(listofwords) #tfidf\n",
    "\n",
    "    tablecolumns = []                      \n",
    "    tablecolumns.append(vectorizer.get_feature_names()) #adding column headers\n",
    "\n",
    "    df = pd.DataFrame(words_tfidf.toarray(), columns=tablecolumns) #creating dataframe\n",
    "\n",
    "    df['Category'] = labels\n",
    "                      \n",
    "    return df\n",
    "\n",
    "\n",
    "df = convertToDataframe(docs[0:50000], labels.values.tolist()[0:50000]) #limit for 50k rows\n",
    "print(df.head(10))\n",
    "\n",
    "end = time. time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data partitioning into train, test and validation set\n",
    "X = df.loc[:, df.columns != 'Category'] #take everything except Category\n",
    "y = df[['Category']] #our label is Category\n",
    "\n",
    "#Split dataset into two groups - the training set and the test set\n",
    "#Test size set to 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "         pred:0  pred:1  pred:2  pred:3  pred:4  pred:5  pred:6  pred:7  \\\n",
      "true:0        0       0       0     180       0       0       0       0   \n",
      "true:1        0       0       0    1051       0       0       0       0   \n",
      "true:2        0       0       0     448       0       0       0       0   \n",
      "true:3        0       0       0    3158       0       0       0       0   \n",
      "true:4        0       0       0    1654       0       0       0       0   \n",
      "true:5        0       0       0    2150       0       0       0       0   \n",
      "true:6        0       0       0      82       0       0       0       0   \n",
      "true:7        0       0       0     464       0       0       0       0   \n",
      "true:8        0       0       0     239       0       0       0       0   \n",
      "true:9        0       0       0     361       0       0       0       0   \n",
      "true:10       0       0       0      47       0       0       0       0   \n",
      "true:11       0       0       0     166       0       0       0       0   \n",
      "\n",
      "         pred:8  pred:9  pred:10  pred:11  \n",
      "true:0        0       0        0        0  \n",
      "true:1        0       0        0        0  \n",
      "true:2        0       0        0        0  \n",
      "true:3        0       0        0        0  \n",
      "true:4        0       0        0        0  \n",
      "true:5        0       0        0        0  \n",
      "true:6        0       0        0        0  \n",
      "true:7        0       0        0        0  \n",
      "true:8        0       0        0        0  \n",
      "true:9        0       0        0        0  \n",
      "true:10       0       0        0        0  \n",
      "true:11       0       0        0        0  \n",
      "Accuracy: 0.3158\n",
      "F1: 0.04000101332522673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Build, train and test a model using Random Forest classifier\n",
    "\n",
    "#Instantiate model with 500 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 500, random_state = 0, max_depth = 2)\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative method:\n",
    "# Find the confusion matrix of the result\n",
    "#cm = confusion_matrix(y_test, y_pred)\n",
    "#print(cm)\n",
    "\n",
    "# Find the accuracy and F1 score of the result\n",
    "#asr = accuracy_score(y_test, y_pred)\n",
    "#f1 = f1_score(y_test, y_pred)\n",
    "#print(\"Accuracy:\", asr)\n",
    "#print(\"F1:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
