{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Before closing, go to Cell > All Output > Clear to keep file size small.\n",
    "\n",
    "Also make sure this jupyter notebook file is opened using the following command:\n",
    "\n",
    "```jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000000```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Creating Reduced Datasets</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "datasize = 20000\n",
    "\n",
    "df = pd.DataFrame(columns=['itemid', 'title', 'Category', 'image_path']) #creating dataframe\n",
    "\n",
    "all_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# sort the dataframe\n",
    "all_df.sort_values(by='Category', inplace=True)\n",
    "\n",
    "# get a list of category\n",
    "mobilelist=list(range(31, 58))\n",
    "fashionlist=list(range(17,31))\n",
    "beautylist=list(range(0, 17))\n",
    "\n",
    "def retrievesample(all_df, list, df):\n",
    "    eachdf = all_df.loc[all_df.Category.isin(list)]\n",
    "\n",
    "    count_row = eachdf.shape[0]  # gives number of row count\n",
    "    print(\"Original Count:\", count_row)\n",
    "    \n",
    "    eachdf = eachdf.sample(datasize) #retrieve a sample\n",
    "\n",
    "    count_row = eachdf.shape[0]  # gives number of row count\n",
    "    print(\"New Sample Count:\", count_row)\n",
    "    \n",
    "    df = df.append(eachdf, ignore_index=True) #append to original dataframe\n",
    "    \n",
    "    return df\n",
    "    \n",
    "df = retrievesample(all_df, mobilelist, df)\n",
    "df = retrievesample(all_df, fashionlist, df)\n",
    "df = retrievesample(all_df, beautylist, df)\n",
    "\n",
    "df.to_csv('train2.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Import all libraries and reading explored data into Dataframe</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import re, io, gensim, datetime, time, nltk, random, pickle\n",
    "from gensim import corpora\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#General libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Libraries for data pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#For Decision Tree implementation\n",
    "from scipy.stats import entropy\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "#For Bagging implementation\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#For AdaBoost implementation\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#For Random Forest implementation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#For Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "string = 'true:'\n",
    "goldtruth = [string+str(i) for i in range(0, 58)]\n",
    "\n",
    "string = 'pred:'\n",
    "prediction = [string+str(i) for i in range(0, 58)]\n",
    "\n",
    "\n",
    "def printModelAccuracy(y_test, y_pred):\n",
    "    # Find the confusion matrix of the result\n",
    "    cm = pd.DataFrame(confusion_matrix(y_test, y_pred, labels=list(range(0, 58))), \\\n",
    "        index=goldtruth, \n",
    "        columns=prediction)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Find the accuracy and F1 score of the result\n",
    "    asr = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"Accuracy:\", asr)\n",
    "    print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Feature Selection</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555044\n",
      "Total Unique Words: 22923\n",
      "Total Most Common Words: 5000\n",
      "['lengan', 'dress', 'wanita', 'untuk', 'neck', 'promo', 'cream', 'panjang', 'powder', 'model']\n",
      "BREAK\n",
      "Total Middle Words: 5000\n",
      "['temprered', '18000mah', '082199992592', '9.0', 'z380', 'e5577', '042cs20869', '4430', 'k270', 'whasapp']\n",
      "BREAK\n",
      "Total Least Common Words: 5000\n",
      "['24632', 'vto', 'i.193', '012', 'khairunnisa', 'butt', 'lucia', 'crg162033', 'varsity', 'fs2666']\n"
     ]
    }
   ],
   "source": [
    "all_df = pd.read_csv(\"train2.csv\",header = 0)\n",
    "corpuslist = all_df[\"title\"]\n",
    "\n",
    "titles = []\n",
    "\n",
    "for title in corpuslist:\n",
    "    eachwordintitle = nltk.word_tokenize(title)\n",
    "    titles += eachwordintitle\n",
    "\n",
    "corpuslist = titles\n",
    "\n",
    "\n",
    "stop_list = nltk.corpus.stopwords.words('english')\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "corpuslist = [w.lower() for w in corpuslist] #lower case the words\n",
    "#corpuslist = [w for w in corpuslist if re.search('^[a-z]+$', w)] #lower case the words\n",
    "#corpuslist = [w for w in corpuslist if w not in stop_list] #lower case the words\n",
    "#corpuslist = [stemmer.stem(w) for w in corpuslist] #lower case the words\n",
    "print(len(corpuslist))\n",
    "\n",
    "fdist = nltk.FreqDist(w for w in corpuslist)\n",
    "\n",
    "totaluniquewords = 0\n",
    "for word in fdist:\n",
    "    totaluniquewords+=1\n",
    "print(\"Total Unique Words:\", totaluniquewords)\n",
    "\n",
    "datasize = 5000\n",
    "#print(datasize)\n",
    "\n",
    "mostcommonwords = fdist.most_common()[:datasize] #top 5k\n",
    "mostcommonwords = [w[0] for w in mostcommonwords]\n",
    "\n",
    "middlewords = fdist.most_common()[int(totaluniquewords/2-datasize/2):int(totaluniquewords/2+datasize/2)] #middle 5k\n",
    "middlewords = [w[0] for w in middlewords]\n",
    "middlewords = random.sample(middlewords, datasize)\n",
    "\n",
    "leastcommonwords = fdist.most_common()[-datasize:] #bottom 5k\n",
    "leastcommonwords = [w[0] for w in leastcommonwords]\n",
    "\n",
    "\n",
    "print(\"Total Most Common Words:\", len(mostcommonwords))\n",
    "print(mostcommonwords[:10])\n",
    "\n",
    "print(\"BREAK\")\n",
    "\n",
    "print(\"Total Middle Words:\", len(middlewords))\n",
    "print(middlewords[:10])\n",
    "\n",
    "print(\"BREAK\")\n",
    "\n",
    "print(\"Total Least Common Words:\", len(leastcommonwords))\n",
    "print(leastcommonwords[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.18136215209961\n",
      "['iphone 5s 32gb gold', 'cash back 50 promo akhir thn beli 2 gratis 1 samsung galaxy s8 pul set wa', 'khusus hari ini 00 garansi resmi handphone oppo f1 s selfie expert 4gb terbaru', 'big promo cuci gudang dijual xiaomi redmi mi a1 black garansi resmi tam murah', 'vivo v5', 'xiaomi mi 5', 'cuci gudang macbook air 11 2015 128gb i5 wa o83i 3612 2666', 'samsung j1 ace terbaru', 'wa ke vivo y69 second', 'promo vivo v 11 original resmi']\n"
     ]
    }
   ],
   "source": [
    "# Takes around 2 minute\n",
    "corpus = all_df[\"title\"]\n",
    "labels = all_df[\"Category\"]\n",
    "itemid = all_df[\"itemid\"]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "def corpus2docs(corpus):\n",
    "    # corpus is a object returned by load_corpus that represents a corpus.\n",
    "    docs1 = []\n",
    "\n",
    "    for title in corpus:\n",
    "        doc = nltk.word_tokenize(title)\n",
    "        docs1.append(doc)\n",
    "    docs2 = [[w.lower() for w in doc] for doc in docs1] #lower case the words\n",
    "    #docs3 = [[w for w in doc if re.search('^[a-z]+$', w)] for doc in docs2] #removing special characters and numbers\n",
    "    #docs4 = [[w for w in doc if w not in stop_list] for doc in docs3] #removing words in stop list\n",
    "    #changing list into a string\n",
    "    #docs5 = [[stemmer.stem(w) for w in doc] for doc in docs4] #changing the words into its root form\n",
    "    \n",
    "    docs5=docs2\n",
    "    #docs2b = docs5 #no feature selection\n",
    "    docs2b = [[w for w in doc if w in mostcommonwords] for doc in docs5] #selecting top 5k words as our features\n",
    "    #docs2b = [[w for w in doc if w in middlewords] for doc in docs5] #selecting middle 5k words as our features\n",
    "    #docs2b = [[w for w in doc if w in leastcommonwords] for doc in docs5] #selecting bottom 5k words as our features\n",
    "    docs2b =  [' '.join([w for w in doc]) for doc in docs2b]\n",
    "    return docs2b\n",
    "\n",
    "docs = corpus2docs(corpus)\n",
    "end = time. time()\n",
    "print(end - start)\n",
    "print(docs[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Vectorise and TFIDF words</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  00  000 0000 000022 00006 00009 0001 00059 00062 0007  \\\n",
      "itemid                                                                    \n",
      "1587581279  0.000000  0.0  0.0    0.0   0.0   0.0  0.0   0.0   0.0  0.0   \n",
      "782441790   0.000000  0.0  0.0    0.0   0.0   0.0  0.0   0.0   0.0  0.0   \n",
      "1332229511  0.394864  0.0  0.0    0.0   0.0   0.0  0.0   0.0   0.0  0.0   \n",
      "829234495   0.000000  0.0  0.0    0.0   0.0   0.0  0.0   0.0   0.0  0.0   \n",
      "134104033   0.000000  0.0  0.0    0.0   0.0   0.0  0.0   0.0   0.0  0.0   \n",
      "1525331944  0.000000  0.0  0.0    0.0   0.0   0.0  0.0   0.0   0.0  0.0   \n",
      "1294311382  0.000000  0.0  0.0    0.0   0.0   0.0  0.0   0.0   0.0  0.0   \n",
      "1543277075  0.000000  0.0  0.0    0.0   0.0   0.0  0.0   0.0   0.0  0.0   \n",
      "1315074632  0.000000  0.0  0.0    0.0   0.0   0.0  0.0   0.0   0.0  0.0   \n",
      "1666658224  0.000000  0.0  0.0    0.0   0.0   0.0  0.0   0.0   0.0  0.0   \n",
      "\n",
      "             ...    zx550ml zx551ml zyfpgs  zyh zyrex zyx2002   zz zzsykd  \\\n",
      "itemid       ...                                                            \n",
      "1587581279   ...        0.0     0.0    0.0  0.0   0.0     0.0  0.0    0.0   \n",
      "782441790    ...        0.0     0.0    0.0  0.0   0.0     0.0  0.0    0.0   \n",
      "1332229511   ...        0.0     0.0    0.0  0.0   0.0     0.0  0.0    0.0   \n",
      "829234495    ...        0.0     0.0    0.0  0.0   0.0     0.0  0.0    0.0   \n",
      "134104033    ...        0.0     0.0    0.0  0.0   0.0     0.0  0.0    0.0   \n",
      "1525331944   ...        0.0     0.0    0.0  0.0   0.0     0.0  0.0    0.0   \n",
      "1294311382   ...        0.0     0.0    0.0  0.0   0.0     0.0  0.0    0.0   \n",
      "1543277075   ...        0.0     0.0    0.0  0.0   0.0     0.0  0.0    0.0   \n",
      "1315074632   ...        0.0     0.0    0.0  0.0   0.0     0.0  0.0    0.0   \n",
      "1666658224   ...        0.0     0.0    0.0  0.0   0.0     0.0  0.0    0.0   \n",
      "\n",
      "           zztim Category  \n",
      "itemid                     \n",
      "1587581279   0.0       31  \n",
      "782441790    0.0       32  \n",
      "1332229511   0.0       41  \n",
      "829234495    0.0       34  \n",
      "134104033    0.0       42  \n",
      "1525331944   0.0       34  \n",
      "1294311382   0.0       35  \n",
      "1543277075   0.0       32  \n",
      "1315074632   0.0       42  \n",
      "1666658224   0.0       42  \n",
      "\n",
      "[10 rows x 22149 columns]\n",
      "2.242906332015991\n"
     ]
    }
   ],
   "source": [
    "# Takes around 10 seconds\n",
    "start = time.time()\n",
    "\n",
    "def convertToDataframe(listofwords, labels,itemid):\n",
    "    vectorizer = TfidfVectorizer(analyzer='word') #tfidf\n",
    "    words_tfidf = vectorizer.fit_transform(listofwords) #tfidf\n",
    "\n",
    "    tablecolumns = []                      \n",
    "    tablecolumns.append(vectorizer.get_feature_names()) #adding column headers\n",
    "\n",
    "    df = pd.DataFrame(words_tfidf.toarray(), columns=tablecolumns, index=itemid) #creating dataframe\n",
    "\n",
    "    df['Category'] = labels\n",
    "                      \n",
    "    return df\n",
    "\n",
    "df = convertToDataframe(docs, labels.values.tolist(),itemid)\n",
    "print(df.head(10))\n",
    "\n",
    "end = time. time()\n",
    "print(end - start)\n",
    "\n",
    "docs = \"\" #clear memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Vectorise and TF words</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           00 000 000mah 001 002 003 006 01 010 0119   ...    zipper zoom  \\\n",
      "itemid                                                 ...                  \n",
      "1587581279  0   0      0   0   0   0   0  0   0    0   ...         0    0   \n",
      "782441790   0   0      0   0   0   0   0  0   0    0   ...         0    0   \n",
      "1332229511  1   0      0   0   0   0   0  0   0    0   ...         0    0   \n",
      "829234495   0   0      0   0   0   0   0  0   0    0   ...         0    0   \n",
      "134104033   0   0      0   0   0   0   0  0   0    0   ...         0    0   \n",
      "1525331944  0   0      0   0   0   0   0  0   0    0   ...         0    0   \n",
      "1294311382  0   0      0   0   0   0   0  0   0    0   ...         0    0   \n",
      "1543277075  0   0      0   0   0   0   0  0   0    0   ...         0    0   \n",
      "1315074632  0   0      0   0   0   0   0  0   0    0   ...         0    0   \n",
      "1666658224  0   0      0   0   0   0   0  0   0    0   ...         0    0   \n",
      "\n",
      "           zoya zr zs620kl zte zuk zv zyrex Category  \n",
      "itemid                                                \n",
      "1587581279    0  0       0   0   0  0     0       31  \n",
      "782441790     0  0       0   0   0  0     0       32  \n",
      "1332229511    0  0       0   0   0  0     0       41  \n",
      "829234495     0  0       0   0   0  0     0       34  \n",
      "134104033     0  0       0   0   0  0     0       42  \n",
      "1525331944    0  0       0   0   0  0     0       34  \n",
      "1294311382    0  0       0   0   0  0     0       35  \n",
      "1543277075    0  0       0   0   0  0     0       32  \n",
      "1315074632    0  0       0   0   0  0     0       42  \n",
      "1666658224    0  0       0   0   0  0     0       42  \n",
      "\n",
      "[10 rows x 4908 columns]\n",
      "1.4556889533996582\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "def convertToDataframe(listofwords, labels,itemid):\n",
    "    vectorizer = CountVectorizer(analyzer='word') #tf\n",
    "    words_tfidf = vectorizer.fit_transform(listofwords) #tf\n",
    "\n",
    "    tablecolumns = []                      \n",
    "    tablecolumns.append(vectorizer.get_feature_names()) #adding column headers\n",
    "\n",
    "    df = pd.DataFrame(words_tfidf.toarray(), columns=tablecolumns,index=itemid) #creating dataframe\n",
    "\n",
    "    df['Category'] = labels\n",
    "                      \n",
    "    return df\n",
    "\n",
    "df = convertToDataframe(docs, labels.values.tolist(),itemid)\n",
    "print(df.head(10))\n",
    "\n",
    "end = time. time()\n",
    "print(end - start)\n",
    "\n",
    "docs = \"\" #clear memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train-Test Split</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'Category'] #take everything except Category\n",
    "\n",
    "y = df[['Category']] #our label is Category\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "df = \"\" #clear memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Naive Bayes to compare which features to select</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "         pred:0  pred:1  pred:2  pred:3  pred:4  pred:5  pred:6  pred:7  \\\n",
      "true:0       15       9       9       3       8       4       1       3   \n",
      "true:1        0     273       5      43      30      62       1       6   \n",
      "true:2        0       2     123       8       8       1       0       3   \n",
      "true:3        0      15       5     934      35      91       0       3   \n",
      "true:4        0       1       0      51     419     101       0       8   \n",
      "true:5        0       3       1      23     109     603       0       5   \n",
      "true:6        0       0       0       4       0       0       0      23   \n",
      "true:7        0       1       0       4      20      11       0     113   \n",
      "true:8        0       0       0       7       2       5       0      14   \n",
      "true:9        0       0       0       8      26      21       0       4   \n",
      "true:10       0       0       0       1       8       0       0       0   \n",
      "true:11       0       0       0      12       2       2       0      10   \n",
      "true:12       0       0       0       0       4       3       0       0   \n",
      "true:13       0       0       0       0       1       2       0       1   \n",
      "true:14       0       0       0       0       0       0       0       0   \n",
      "true:15       0       0       0       0       0       0       0       0   \n",
      "true:16       0       0       0       0       1       0       0       0   \n",
      "true:17       0       0       0       0       0       0       0       0   \n",
      "true:18       0       0       0       0       0       0       0       0   \n",
      "true:19       0       0       0       0       0       0       0       0   \n",
      "true:20       0       0       0       0       0       0       0       0   \n",
      "true:21       0       0       0       0       0       0       0       0   \n",
      "true:22       0       0       0       0       0       0       0       0   \n",
      "true:23       0       0       0       0       0       0       0       0   \n",
      "true:24       0       0       0       0       0       0       0       0   \n",
      "true:25       0       0       0       0       0       0       0       0   \n",
      "true:26       0       0       0       0       0       0       0       0   \n",
      "true:27       0       0       0       0       0       0       0       0   \n",
      "true:28       0       0       0       0       0       0       0       0   \n",
      "true:29       0       0       0       0       0       0       0       0   \n",
      "true:30       0       0       0       0       0       0       0       0   \n",
      "true:31       0       0       0       0       0       0       0       0   \n",
      "true:32       0       0       0       0       0       0       0       0   \n",
      "true:33       0       0       0       0       0       0       0       0   \n",
      "true:34       0       0       0       0       0       0       0       0   \n",
      "true:35       0       0       0       0       0       0       0       0   \n",
      "true:36       0       0       0       0       0       0       0       0   \n",
      "true:37       0       0       0       0       0       0       0       0   \n",
      "true:38       0       0       0       0       0       0       0       0   \n",
      "true:39       0       0       0       0       0       0       0       0   \n",
      "true:40       0       0       0       0       0       0       0       0   \n",
      "true:41       0       0       0       0       0       0       0       0   \n",
      "true:42       0       0       0       0       0       0       0       0   \n",
      "true:43       0       0       0       0       0       0       0       0   \n",
      "true:44       0       0       0       0       0       0       0       0   \n",
      "true:45       0       0       0       0       0       0       0       0   \n",
      "true:46       0       0       0       0       0       0       0       0   \n",
      "true:47       0       0       0       0       0       0       0       0   \n",
      "true:48       0       0       0       0       0       0       0       0   \n",
      "true:49       0       0       0       0       0       0       0       0   \n",
      "true:50       0       0       0       0       0       0       0       0   \n",
      "true:51       0       0       0       0       0       0       0       0   \n",
      "true:52       0       0       0       0       0       0       0       0   \n",
      "true:53       0       0       0       0       0       0       0       0   \n",
      "true:54       0       0       0       0       0       0       0       0   \n",
      "true:55       0       0       0       0       0       0       0       0   \n",
      "true:56       0       0       0       0       0       0       0       0   \n",
      "true:57       0       0       0       0       0       0       0       0   \n",
      "\n",
      "         pred:8  pred:9   ...     pred:48  pred:49  pred:50  pred:51  pred:52  \\\n",
      "true:0        1       0   ...           0        0        0        0        0   \n",
      "true:1        2       0   ...           0        0        0        0        0   \n",
      "true:2        6       1   ...           0        0        0        0        0   \n",
      "true:3        6       0   ...           0        0        0        0        0   \n",
      "true:4        5       3   ...           0        0        0        0        0   \n",
      "true:5        0       1   ...           0        0        0        0        0   \n",
      "true:6        5       0   ...           0        0        0        0        0   \n",
      "true:7        1       2   ...           0        0        0        0        0   \n",
      "true:8       35       2   ...           0        0        0        0        0   \n",
      "true:9        0      40   ...           0        0        0        0        0   \n",
      "true:10       0       5   ...           0        0        0        0        0   \n",
      "true:11       5       0   ...           0        0        0        0        0   \n",
      "true:12       0       0   ...           0        0        0        0        0   \n",
      "true:13       0       0   ...           0        0        0        0        0   \n",
      "true:14       0       0   ...           0        0        0        0        0   \n",
      "true:15       0       0   ...           0        0        0        0        0   \n",
      "true:16       0       0   ...           0        0        0        0        0   \n",
      "true:17       0       0   ...           0        0        0        0        0   \n",
      "true:18       0       0   ...           0        0        0        0        0   \n",
      "true:19       0       0   ...           0        0        0        0        0   \n",
      "true:20       0       0   ...           0        0        0        0        0   \n",
      "true:21       0       0   ...           0        0        0        0        0   \n",
      "true:22       0       0   ...           0        0        0        0        0   \n",
      "true:23       0       0   ...           0        0        0        0        0   \n",
      "true:24       0       0   ...           0        0        0        0        0   \n",
      "true:25       0       0   ...           0        0        0        0        0   \n",
      "true:26       0       0   ...           0        0        0        0        0   \n",
      "true:27       0       0   ...           0        0        0        0        0   \n",
      "true:28       0       0   ...           0        0        0        0        0   \n",
      "true:29       0       0   ...           0        0        0        0        0   \n",
      "true:30       0       0   ...           0        0        0        0        0   \n",
      "true:31       0       0   ...           0        0        0        0        0   \n",
      "true:32       0       0   ...           0        0        0        0        0   \n",
      "true:33       0       0   ...           0        0        0        0        0   \n",
      "true:34       0       0   ...           0        0        0        0        0   \n",
      "true:35       0       0   ...           0        0        0        0        0   \n",
      "true:36       0       0   ...           0        0        0        0        0   \n",
      "true:37       0       0   ...           0        0        0        0        0   \n",
      "true:38       0       0   ...           0        0        0        0        0   \n",
      "true:39       0       0   ...           0        0        0        0        0   \n",
      "true:40       0       0   ...           0        0        0        0        0   \n",
      "true:41       0       0   ...           0        0        0        0        0   \n",
      "true:42       0       0   ...           0        0        0        0        0   \n",
      "true:43       0       0   ...           0        0        0        0        0   \n",
      "true:44       0       0   ...           0        0        0        0        0   \n",
      "true:45       0       0   ...           0        0        0        0        0   \n",
      "true:46       0       0   ...           0        0        0        0        0   \n",
      "true:47       0       0   ...           0        0        0        0        0   \n",
      "true:48       0       0   ...           0        0        0        0        0   \n",
      "true:49       0       0   ...           0        0        0        0        0   \n",
      "true:50       0       0   ...           0        0        0        0        0   \n",
      "true:51       0       0   ...           0        0        0        0        0   \n",
      "true:52       0       0   ...           0        0        0        0        0   \n",
      "true:53       0       0   ...           0        0        0        0        0   \n",
      "true:54       0       0   ...           0        0        0        0        0   \n",
      "true:55       0       0   ...           0        0        0        0        0   \n",
      "true:56       0       0   ...           0        0        0        0        0   \n",
      "true:57       0       0   ...           0        0        0        0        0   \n",
      "\n",
      "         pred:53  pred:54  pred:55  pred:56  pred:57  \n",
      "true:0         0        0        0        0        0  \n",
      "true:1         0        0        0        0        0  \n",
      "true:2         0        0        0        0        0  \n",
      "true:3         0        0        0        0        0  \n",
      "true:4         0        0        0        0        0  \n",
      "true:5         0        0        0        0        0  \n",
      "true:6         0        0        0        0        0  \n",
      "true:7         0        0        0        0        0  \n",
      "true:8         0        0        0        0        0  \n",
      "true:9         0        0        0        0        0  \n",
      "true:10        0        0        0        0        0  \n",
      "true:11        0        0        0        0        0  \n",
      "true:12        0        0        0        0        0  \n",
      "true:13        0        0        0        0        0  \n",
      "true:14        0        0        0        0        0  \n",
      "true:15        0        0        0        0        0  \n",
      "true:16        0        0        0        0        0  \n",
      "true:17        0        0        0        0        0  \n",
      "true:18        0        0        0        0        0  \n",
      "true:19        0        0        0        0        0  \n",
      "true:20        0        0        0        0        0  \n",
      "true:21        0        0        0        0        0  \n",
      "true:22        0        0        0        0        0  \n",
      "true:23        0        0        0        0        0  \n",
      "true:24        0        0        0        0        0  \n",
      "true:25        0        0        0        0        0  \n",
      "true:26        0        0        0        0        0  \n",
      "true:27        0        0        0        0        0  \n",
      "true:28        0        0        0        0        0  \n",
      "true:29        0        0        0        0        0  \n",
      "true:30        0        0        0        0        0  \n",
      "true:31        0        0        0        0        0  \n",
      "true:32        0        0        0        0        0  \n",
      "true:33        0        0        0        0        0  \n",
      "true:34        0        0        0        0        0  \n",
      "true:35        0        0        0        0        0  \n",
      "true:36        0        0        0        0        0  \n",
      "true:37        0        0        0        0        0  \n",
      "true:38        0        0        0        0        0  \n",
      "true:39        0        0        0        0        0  \n",
      "true:40        0        0        0        0        0  \n",
      "true:41        0        0        0        0        0  \n",
      "true:42        0        0        0        0        0  \n",
      "true:43        0        0        0        0        0  \n",
      "true:44        0        0        0        0        0  \n",
      "true:45        0        0        0        0        0  \n",
      "true:46        0        0        0        0        0  \n",
      "true:47        0        0        0        0        0  \n",
      "true:48        0        0        0        0        0  \n",
      "true:49        0        0        0        0        0  \n",
      "true:50        0        0        0        0        0  \n",
      "true:51        0        0        0        0        0  \n",
      "true:52        0        0        0        0        0  \n",
      "true:53        0        0        0        0        0  \n",
      "true:54        0        0        0        0        0  \n",
      "true:55        0        0        0        0        0  \n",
      "true:56        0        0        0        0        0  \n",
      "true:57        0        0        0        0        0  \n",
      "\n",
      "[58 rows x 58 columns]\n",
      "Accuracy: 0.6509166666666667\n",
      "F1: 0.3145468969758736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "naivebayes = MultinomialNB()\n",
    "#Fit the training feature Xs and training label Ys\n",
    "naivebayes.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = naivebayes.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Save Dataframe to file</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle(\"X_train_best_choice_7\")\n",
    "X_test.to_pickle(\"X_test_best_choice_7\")\n",
    "y_train.to_pickle(\"y_train_best_choice_7\")\n",
    "y_test.to_pickle(\"y_test_best_choice_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           00 000 000mah 001 002 003 006 01 010 0119   ...    zipper zoom  \\\n",
      "itemid                                                 ...                  \n",
      "1677148667  0   0      0   0   0   0   0  0   0    0   ...         0    0   \n",
      "1066475273  0   0      0   0   0   0   0  0   0    0   ...         0    0   \n",
      "176845790   0   0      0   0   0   0   0  0   0    0   ...         0    0   \n",
      "1824729105  0   0      0   0   0   0   0  0   0    0   ...         0    0   \n",
      "1656487109  0   0      0   0   0   0   0  0   0    0   ...         0    0   \n",
      "\n",
      "           zoya zr zs620kl zte zuk zv zyrex Category  \n",
      "itemid                                                \n",
      "1677148667    0  0       0   0   0  0     0       32  \n",
      "1066475273    0  0       0   0   0  0     0       35  \n",
      "176845790     0  0       0   0   0  0     0        7  \n",
      "1824729105    0  0       0   0   0  0     0       22  \n",
      "1656487109    0  0       0   0   0  0     0        5  \n",
      "\n",
      "[5 rows x 4908 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           aa aaa aap ab abang abaya abg abh abi ablif   ...    zoya zp zpa  \\\n",
      "itemid                                                   ...                  \n",
      "1677148667  0   0   0  0     0     0   0   0   0     0   ...       0  0   0   \n",
      "1066475273  0   0   0  0     0     0   0   0   0     0   ...       0  0   0   \n",
      "176845790   0   0   0  0     0     0   0   0   0     0   ...       0  0   0   \n",
      "1824729105  0   0   0  0     0     0   0   0   0     0   ...       0  0   0   \n",
      "1656487109  0   0   0  0     0     0   0   0   0     0   ...       0  0   0   \n",
      "\n",
      "           zr zte zuk zv zyh zyrex Category  \n",
      "itemid                                       \n",
      "1677148667  0   0   0  0   0     0       32  \n",
      "1066475273  0   0   0  0   0     0       35  \n",
      "176845790   0   0   0  0   0     0        7  \n",
      "1824729105  0   0   0  0   0     0       22  \n",
      "1656487109  0   0   0  0   0     0        5  \n",
      "\n",
      "[5 rows x 4983 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
